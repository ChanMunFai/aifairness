{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MF 2022_IC_ai_fairness_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChanMunFai/aifairness/blob/main/MF_2022_IC_ai_fairness_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiNaI-VawFG4"
      },
      "source": [
        "## Notebook for the Tutorial session of the Machine Learning module of the Ethics, Privacy and AI in Society course.\n",
        "\n",
        "In this notebook, we will train a simple classifier on a dataset that has an internal bias in its datapoints. We will use the **AI Fairness 360** library to implement a de-biasing method, and also to observe the performance of our classifier using a series of metrics, that go beyond pure accuracy.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzFppAdYxVpu"
      },
      "source": [
        "Install the library and download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ2kq6rNqGro"
      },
      "source": [
        "!pip install 'aif360[LFR]'\n",
        "!pip install fairlearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS0AD740qd5T",
        "outputId": "89c740c5-b526-4739-fcbf-315823d0de24"
      },
      "source": [
        "cd /usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9dbNroSqfSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6840a2-cd98-44a5-f6eb-da8f84ee5740"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-04 09:00:45--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3974305 (3.8M) [application/x-httpd-php]\n",
            "Saving to: ‘adult.data’\n",
            "\n",
            "adult.data          100%[===================>]   3.79M  7.31MB/s    in 0.5s    \n",
            "\n",
            "2022-02-04 09:00:46 (7.31 MB/s) - ‘adult.data’ saved [3974305/3974305]\n",
            "\n",
            "--2022-02-04 09:00:46--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5229 (5.1K) [application/x-httpd-php]\n",
            "Saving to: ‘adult.names’\n",
            "\n",
            "adult.names         100%[===================>]   5.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-04 09:00:46 (108 MB/s) - ‘adult.names’ saved [5229/5229]\n",
            "\n",
            "--2022-02-04 09:00:46--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2003153 (1.9M) [application/x-httpd-php]\n",
            "Saving to: ‘adult.test’\n",
            "\n",
            "adult.test          100%[===================>]   1.91M  4.25MB/s    in 0.4s    \n",
            "\n",
            "2022-02-04 09:00:47 (4.25 MB/s) - ‘adult.test’ saved [2003153/2003153]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPJDsQtqxaLn"
      },
      "source": [
        "#STEP 1: Import the libraries and set the random seed.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from aif360.datasets import StructuredDataset, BinaryLabelDataset\n",
        "from aif360.datasets import AdultDataset\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
        "\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
        "\n",
        "import pdb\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler  #MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import *\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDkHVXGlxhs1",
        "outputId": "11f1a54e-9176-41c5-cd28-269a2f397601"
      },
      "source": [
        "#STEP 2: We define where's the bias in the features of our dataset.\n",
        "\n",
        "privileged_groups = [{'sex': 1}]\n",
        "unprivileged_groups = [{'sex': 0}]\n",
        "dataset_orig = load_preproc_data_adult(['sex'])\n",
        "\n",
        "\n",
        "#STEP 3: We split between training and test set.\n",
        "train, test = dataset_orig.split([0.7], shuffle=True)\n",
        "print(\"training data size\", train.features.shape)\n",
        "print(\"dataset feature names\", train.feature_names)\n",
        "\n",
        "#Normalize the dataset, both train and test. This should always be done in any machine learning pipeline!\n",
        "scale_orig = StandardScaler()\n",
        "X_train = scale_orig.fit_transform(train.features)\n",
        "y_train = train.labels.ravel()\n",
        "\n",
        "untransformed_X = scale_orig.inverse_transform(X_train)\n",
        "\n",
        "X_test = scale_orig.fit_transform(test.features)\n",
        "y_test = test.labels.ravel()\n",
        "\n",
        "print(untransformed_X)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data size (34189, 18)\n",
            "dataset feature names ['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n",
            "[[1.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 1.00000000e+00]\n",
            " [1.11022302e-16 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 1.00000000e+00]\n",
            " ...\n",
            " [1.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 0.00000000e+00 ... 1.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW00WHLYQifr",
        "outputId": "b010c2bf-9c80-496c-d734-691dbd4f463b"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               instance weights features  ...                     labels\n",
            "                                          ...                           \n",
            "                                    race  ... Education Years=>12       \n",
            "instance names                            ...                           \n",
            "723                         1.0      0.0  ...                 0.0    0.0\n",
            "25734                       1.0      1.0  ...                 1.0    1.0\n",
            "18152                       1.0      0.0  ...                 0.0    0.0\n",
            "20053                       1.0      1.0  ...                 0.0    0.0\n",
            "264                         1.0      1.0  ...                 1.0    0.0\n",
            "...                         ...      ...  ...                 ...    ...\n",
            "42249                       1.0      0.0  ...                 0.0    0.0\n",
            "37193                       1.0      1.0  ...                 0.0    0.0\n",
            "12260                       1.0      1.0  ...                 1.0    0.0\n",
            "47789                       1.0      1.0  ...                 1.0    0.0\n",
            "38103                       1.0      1.0  ...                 0.0    0.0\n",
            "\n",
            "[14653 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(test))\n",
        "print(test.feature_names)\n",
        "print(test.labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf576EZ990M8",
        "outputId": "48152ed6-36d8-4c93-f3e4-e6b49144fd90"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_de_dummy_code_df', '_parse_feature_names', 'align_datasets', 'convert_to_dataframe', 'copy', 'export_dataset', 'favorable_label', 'feature_names', 'features', 'ignore_fields', 'import_dataset', 'instance_names', 'instance_weights', 'label_names', 'labels', 'metadata', 'privileged_protected_attributes', 'protected_attribute_names', 'protected_attributes', 'scores', 'split', 'subset', 'temporarily_ignore', 'unfavorable_label', 'unprivileged_protected_attributes', 'validate_dataset']\n",
            "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " ...\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tL0BFwnzTsu",
        "outputId": "01797ee4-94ef-412f-ae80-e19a44da68c8"
      },
      "source": [
        "#STEP 4: Train a standard classifier, compute accuracy and fairness metrics.\n",
        "#We use a simple Logistic Regression to parametrise our classifier. \n",
        "#You can try different classifiers and hyperparameters, checking how the metrics will change.\n",
        "\n",
        "learner = LogisticRegression(solver='liblinear', random_state=1)  #(C=reg_best, solver='liblinear', random_state=1) \n",
        "learner.fit(X_train,y_train)\n",
        "predictions = learner.predict(X_test)\n",
        "\n",
        "test_pred = test.copy()\n",
        "test_pred.labels = predictions\n",
        "\n",
        "print(\"Accuracy\", sum(predictions==y_test)/len(y_test))\n",
        "\n",
        "#This is the set of metrics we use, taken from https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.ClassificationMetric.html.\n",
        "#In different forms, they all measure bias. \n",
        "metric = ClassificationMetric(test, test_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "metric_arrs = {}\n",
        "#Statistical Parity Difference measures the difference of the above values instead of ratios, hence we\n",
        "#would like it to be close to 0.\n",
        "metric_arrs['stat_par_diff']=(metric.statistical_parity_difference())\n",
        "#Equal opportunity difference measures the ability of the classifier to accurately classify a datapoint as positive\n",
        "#regardless of the presence of the unpriviliged feature. We would like it to be close to 0. A negative value signals bias\n",
        "#towards priviliged.\n",
        "metric_arrs['eq_opp_diff']=(metric.equal_opportunity_difference())\n",
        "#Average of difference in FPR and TPR for unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
        "metric_arrs['avg_odds_diff']=(metric.average_odds_difference())\n",
        "#Balanced accuracy is a general metric, not dependent on bias. We would like to have it close to 1, meaning \n",
        "#that the classifier can equally detect positive and negative classes.\n",
        "metric_arrs['bal_acc']=((metric.true_positive_rate() + metric.true_negative_rate()) / 2)\n",
        "#We would like Disparate Impact to be close to 1. It measures the ratio between the likelihood of the class being\n",
        "#predicted as positive if we have the unpriviliged feature and the the same likelihood with the priviliged feature.\n",
        "#Values close to 0 indicate strong bias.\n",
        "metric_arrs['disp_imp']=(metric.disparate_impact())\n",
        "print(metric_arrs)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8042039172865625\n",
            "{'stat_par_diff': -0.20557244174265452, 'eq_opp_diff': -0.4414141414141414, 'avg_odds_diff': -0.27273605621431707, 'bal_acc': 0.657262071666589, 'disp_imp': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJhrtPG5zVF4"
      },
      "source": [
        "Take a look at the metrics. Do you see a bias, given the metrics we used?\n",
        "Let's use **Reweighing**, a method to tackle dataset bias by applying a weight to the training datapoints, so that some are considered more than others in the computation of the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjQVEWIkp9pv",
        "outputId": "3abb26b2-34fa-4447-91ec-93d5a916d542"
      },
      "source": [
        "\n",
        "#STEP 5: Mitigate the bias, e.g. by transforming the original dataset via reweighing.\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "#We obtain a set of weights for the training set, to use in scikit-learn.\n",
        "train = RW.fit_transform(train)\n",
        "\n",
        "print(\"subgroup weights\", np.unique(train.instance_weights))\n",
        "\n",
        "#We use the same classifier as before, but now we use the instance weights in the training phase.\n",
        "learner = LogisticRegression(solver='liblinear', random_state=1)  #(C=reg_best, solver='liblinear', random_state=1) \n",
        "learner.fit(X_train,y_train,sample_weight=train.instance_weights)\n",
        "predictions = learner.predict(X_test)\n",
        "print(\"Accuracy\", sum(predictions==y_test)/len(y_test))\n",
        "\n",
        "\n",
        "test_pred = test.copy()\n",
        "predictions.resize((len(predictions),1))\n",
        "test_pred.labels = predictions\n",
        "\n",
        "metric = ClassificationMetric(test, test_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "metric_arrs = {}\n",
        "metric_arrs['stat_par_diff']=(metric.statistical_parity_difference())\n",
        "metric_arrs['eq_opp_diff']=(metric.equal_opportunity_difference())\n",
        "metric_arrs['avg_odds_diff']=(metric.average_odds_difference())\n",
        "metric_arrs['bal_acc']=((metric.true_positive_rate()                             + metric.true_negative_rate()) / 2)\n",
        "metric_arrs['disp_imp']=(metric.disparate_impact())\n",
        "print(metric_arrs)\n",
        "\n",
        "#pdb.set_trace()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subgroup weights [0.78875735 0.85514075 1.09270553 2.1493453 ]\n",
            "Accuracy 0.7905548351873336\n",
            "{'stat_par_diff': -0.05772377304710344, 'eq_opp_diff': 0.03513180586351322, 'avg_odds_diff': 0.019935709638750347, 'bal_acc': 0.6671783946216994, 'disp_imp': 0.706625314122085}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idMo4DNzwCaw"
      },
      "source": [
        "Take another look at the metrics. Is the situation better in terms of bias? What about the accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(**TASK 1**) For each of the subgroup (combinations of YxS), build your code to compute the weights based on lecture slides. Verify the weights are the same as when using the library. \n",
        "\n",
        "(**TASK 2**) On the accuracy and generalisation trade-off: Change the regularisation strength via a hyperparameter setting. In logistic regression, use:`LogisticRegression(C=C_value) `.\n",
        "How does this change the accuracy and fairness metrics? \n",
        "\n",
        "(**TASK 3**) Using train data, perform 5-fold cross validation; by varying the trade-off hyperparameter, select the model with the highest accuracy, and evaluate it on the test data (**assignment**).\n",
        "\n",
        "(**TASK 4**) Learn about different pre-, in-, or post-processing methods and how to evaluate them using the library. Perform empirical analysis on accuracy and fairness trade-off (**assignment**).\n",
        "\n"
      ],
      "metadata": {
        "id": "M83MmtkUBcrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-weighing\n",
        "\n",
        "Compute weights for all combinations of Y (outcome) and A(sensitive attribute)\n",
        "\n",
        "Intuition is to force Y and A to be independent.\n"
      ],
      "metadata": {
        "id": "kn-czg4T8CI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2"
      ],
      "metadata": {
        "id": "qQmPQ0t28iHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner = LogisticRegression(solver='liblinear', random_state=1, C = 0.01, penalty = \"l2\")  #(C=reg_best, solver='liblinear', random_state=1) \n",
        "learner.fit(X_train,y_train)\n",
        "predictions = learner.predict(X_test)\n",
        "\n",
        "test_pred = test.copy()\n",
        "test_pred.labels = predictions\n",
        "\n",
        "print(\"Accuracy\", sum(predictions==y_test)/len(y_test))\n",
        "\n",
        "metric = ClassificationMetric(test, test_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "metric_arrs = {}\n",
        "metric_arrs['stat_par_diff']=(metric.statistical_parity_difference())\n",
        "metric_arrs['eq_opp_diff']=(metric.equal_opportunity_difference())\n",
        "metric_arrs['avg_odds_diff']=(metric.average_odds_difference())\n",
        "metric_arrs['bal_acc']=((metric.true_positive_rate() + metric.true_negative_rate()) / 2)\n",
        "metric_arrs['disp_imp']=(metric.disparate_impact())\n",
        "print(metric_arrs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi0TFITc8PLo",
        "outputId": "b2275e76-9a6f-4239-c3f6-bd57f74d11e0"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8100730225892309\n",
            "{'stat_par_diff': -0.21391963919639195, 'eq_opp_diff': -0.47379100439634764, 'avg_odds_diff': -0.2873440975798476, 'bal_acc': 0.6695087466257853, 'disp_imp': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test)\n",
        "print(test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "e6N3uGRTLDVa",
        "outputId": "b5657af8-b868-4abd-9050-3f7361121f65"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               instance weights features  ...                     labels\n",
            "                                          ...                           \n",
            "                                    race  ... Education Years=>12       \n",
            "instance names                            ...                           \n",
            "723                         1.0      0.0  ...                 0.0    0.0\n",
            "25734                       1.0      1.0  ...                 1.0    1.0\n",
            "18152                       1.0      0.0  ...                 0.0    0.0\n",
            "20053                       1.0      1.0  ...                 0.0    0.0\n",
            "264                         1.0      1.0  ...                 1.0    0.0\n",
            "...                         ...      ...  ...                 ...    ...\n",
            "42249                       1.0      0.0  ...                 0.0    0.0\n",
            "37193                       1.0      1.0  ...                 0.0    0.0\n",
            "12260                       1.0      1.0  ...                 1.0    0.0\n",
            "47789                       1.0      1.0  ...                 1.0    0.0\n",
            "38103                       1.0      1.0  ...                 0.0    0.0\n",
            "\n",
            "[14653 rows x 20 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-109e4004925e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aif360/datasets/structured_dataset.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'instance_weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mhighest_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'instance weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aif360/datasets/structured_dataset.py\u001b[0m in \u001b[0;36mconvert_to_dataframe\u001b[0;34m(self, de_dummy_code, sep, set_category)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \"\"\"\n\u001b[0;32m--> 387\u001b[0;31m         df = pd.DataFrame(np.hstack((self.features, self.labels)),\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             index=self.instance_names)\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Task 3\n",
        "\n",
        "Link for Cross-Validation: https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "- Use cross_validate()\n",
        "\n",
        "Link to use your own score for CV: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n"
      ],
      "metadata": {
        "id": "awlwQyby-x1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seemes easier to use numpy for CV instead, so let me do that"
      ],
      "metadata": {
        "id": "s3whL_Slh5Oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test.feature_names)\n",
        "column_names = test.feature_names.copy()\n",
        "print(column_names)\n",
        "# print(test.label_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R80ynZz9k5l",
        "outputId": "a158a3b7-a6a3-444c-c0ec-f6db6947297f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.internals.blocks import external_values\n",
        "import pandas as pd\n",
        "from aif360.metrics import DatasetMetric\n",
        "\n",
        "def k_fold_cross_validation(X, y, k, model, feature_names, unprivileged_groups = None, privileged_groups = None): \n",
        "  fold_indices = np.arange(X.shape[0])\n",
        "  np.random.shuffle(fold_indices)\n",
        "\n",
        "  eval_indices = np.array_split(fold_indices, k)\n",
        "\n",
        "  metrics = {}\n",
        "  accuracy_list = []\n",
        "  feature_names = feature_names.copy()\n",
        "  feature_names.extend([\"Label\"])\n",
        "  \n",
        "  # k-fold cross validation \n",
        "  for e in eval_indices:\n",
        "    # print(len(e))\n",
        "\n",
        "    eval_set_X = X[e]\n",
        "    eval_set_X = scale_orig.inverse_transform(eval_set_X).round(1)\n",
        "    eval_set_Y = y[e]\n",
        "    mask_eval = np.ones(X.shape[0], bool)\n",
        "    mask_eval[e] = False\n",
        "\n",
        "    train_set_X = X[mask_eval]\n",
        "    train_set_Y = y[mask_eval]\n",
        "    # print(eval_set_X.shape, train_set_X.shape)\n",
        "\n",
        "    model.fit(train_set_X, train_set_Y)\n",
        "\n",
        "    predictions = model.predict(eval_set_X)\n",
        "    accuracy = sum(predictions == eval_set_Y)/len(eval_set_Y)\n",
        "    accuracy_list.append(accuracy)\n",
        "\n",
        "    # Use AIFairness360 metrics \n",
        "    eval = np.concatenate((eval_set_X, eval_set_Y.reshape(-1, 1)), axis = 1)\n",
        "    eval = pd.DataFrame(eval)\n",
        "    eval = eval.astype(int)\n",
        "    \n",
        "    eval.columns = feature_names\n",
        "\n",
        "    test_pred = eval.copy()\n",
        "    test_pred.iloc[:, -1] = predictions\n",
        "\n",
        "    eval = BinaryLabelDataset(favorable_label=1,unfavorable_label=0,\n",
        "                              df=eval,label_names=['Label'],\n",
        "                              protected_attribute_names=[\"race\", \"sex\"])\n",
        "    \n",
        "    test_pred = BinaryLabelDataset(favorable_label=1,unfavorable_label=0,\n",
        "                              df=test_pred,label_names=['Label'],\n",
        "                              protected_attribute_names=[\"race\", \"sex\"])\n",
        "    \n",
        "    print(eval)\n",
        "    # print(eval.unprivileged_protected_attributes)\n",
        "    \n",
        "    # test_pred = eval.copy()\n",
        "    # test_pred.labels= predictions\n",
        "    print(test_pred)\n",
        "\n",
        "    dm = DatasetMetric(eval, unprivileged_groups, privileged_groups)\n",
        "    print(dm.num_instances(True))\n",
        "    print(dm.num_instances(False))\n",
        "\n",
        "  \n",
        "    metric = ClassificationMetric(eval, test_pred, unprivileged_groups, privileged_groups)\n",
        "    print(metric.accuracy())\n",
        "    print(metric.base_rate())\n",
        "    print(metric.base_rate(True))\n",
        "    print(metric.average_odds_difference())\n",
        "    print(metric.statistical_parity_difference())\n",
        "    print(metric.equal_opportunity_difference())\n",
        "    print(metric.average_odds_difference())\n",
        "    print((metric.true_positive_rate() + metric.true_negative_rate()) / 2)\n",
        "    print(metric.disparate_impact())\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "  mean_accuracy = np.mean(accuracy_list)\n",
        "  accuracy_list.append(mean_accuracy)\n",
        "\n",
        "  metrics[\"Accuracy\"] = accuracy_list\n",
        "\n",
        "  return eval\n"
      ],
      "metadata": {
        "id": "UE9nCc-2h9c0"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "privileged_groups = [{'sex': 1}]\n",
        "unprivileged_groups = [{'sex': 0}]\n",
        "logistic_regression = LogisticRegression(solver='liblinear', random_state=1, C = 0.01, penalty = \"l2\") \n",
        "eval_a = k_fold_cross_validation(X_train, y_train, k = 2, model = logistic_regression, feature_names = column_names, \n",
        "                        unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrqYtNezjYWR",
        "outputId": "1d66e602-da35-4313-db18-db16208e9a9a"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               instance weights            features  ...                     labels\n",
            "                                protected attribute  ...                           \n",
            "                                               race  ... Education Years=>12       \n",
            "instance names                                       ...                           \n",
            "0                           1.0                 1.0  ...                 0.0    0.0\n",
            "1                           1.0                 1.0  ...                 0.0    0.0\n",
            "2                           1.0                 1.0  ...                 0.0    0.0\n",
            "3                           1.0                 0.0  ...                 0.0    0.0\n",
            "4                           1.0                 1.0  ...                 1.0    1.0\n",
            "...                         ...                 ...  ...                 ...    ...\n",
            "17090                       1.0                 1.0  ...                 1.0    1.0\n",
            "17091                       1.0                 1.0  ...                 1.0    1.0\n",
            "17092                       1.0                 1.0  ...                 0.0    0.0\n",
            "17093                       1.0                 0.0  ...                 0.0    0.0\n",
            "17094                       1.0                 1.0  ...                 0.0    0.0\n",
            "\n",
            "[17095 rows x 20 columns]\n",
            "               instance weights            features  ...                     labels\n",
            "                                protected attribute  ...                           \n",
            "                                               race  ... Education Years=>12       \n",
            "instance names                                       ...                           \n",
            "0                           1.0                 1.0  ...                 0.0    0.0\n",
            "1                           1.0                 1.0  ...                 0.0    0.0\n",
            "2                           1.0                 1.0  ...                 0.0    0.0\n",
            "3                           1.0                 0.0  ...                 0.0    0.0\n",
            "4                           1.0                 1.0  ...                 1.0    0.0\n",
            "...                         ...                 ...  ...                 ...    ...\n",
            "17090                       1.0                 1.0  ...                 1.0    0.0\n",
            "17091                       1.0                 1.0  ...                 1.0    0.0\n",
            "17092                       1.0                 1.0  ...                 0.0    0.0\n",
            "17093                       1.0                 0.0  ...                 0.0    0.0\n",
            "17094                       1.0                 1.0  ...                 0.0    0.0\n",
            "\n",
            "[17095 rows x 20 columns]\n",
            "11431.0\n",
            "5664.0\n",
            "0.7671833869552501\n",
            "0.0\n",
            "0.0\n",
            "nan\n",
            "-0.18975496308729312\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "0.35825769732223445\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "invalid value encountered in double_scalars\n",
            "invalid value encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               instance weights            features  ...                     labels\n",
            "                                protected attribute  ...                           \n",
            "                                               race  ... Education Years=>12       \n",
            "instance names                                       ...                           \n",
            "0                           1.0                 1.0  ...                 0.0    0.0\n",
            "1                           1.0                 1.0  ...                 0.0    0.0\n",
            "2                           1.0                 0.0  ...                 1.0    0.0\n",
            "3                           1.0                 1.0  ...                 0.0    0.0\n",
            "4                           1.0                 1.0  ...                 0.0    0.0\n",
            "...                         ...                 ...  ...                 ...    ...\n",
            "17089                       1.0                 1.0  ...                 1.0    0.0\n",
            "17090                       1.0                 1.0  ...                 1.0    1.0\n",
            "17091                       1.0                 1.0  ...                 0.0    0.0\n",
            "17092                       1.0                 1.0  ...                 0.0    0.0\n",
            "17093                       1.0                 1.0  ...                 0.0    1.0\n",
            "\n",
            "[17094 rows x 20 columns]\n",
            "               instance weights            features  ...                     labels\n",
            "                                protected attribute  ...                           \n",
            "                                               race  ... Education Years=>12       \n",
            "instance names                                       ...                           \n",
            "0                           1.0                 1.0  ...                 0.0    0.0\n",
            "1                           1.0                 1.0  ...                 0.0    0.0\n",
            "2                           1.0                 0.0  ...                 1.0    0.0\n",
            "3                           1.0                 1.0  ...                 0.0    0.0\n",
            "4                           1.0                 1.0  ...                 0.0    0.0\n",
            "...                         ...                 ...  ...                 ...    ...\n",
            "17089                       1.0                 1.0  ...                 1.0    0.0\n",
            "17090                       1.0                 1.0  ...                 1.0    0.0\n",
            "17091                       1.0                 1.0  ...                 0.0    0.0\n",
            "17092                       1.0                 1.0  ...                 0.0    0.0\n",
            "17093                       1.0                 1.0  ...                 0.0    0.0\n",
            "\n",
            "[17094 rows x 20 columns]\n",
            "11435.0\n",
            "5659.0\n",
            "0.7596817596817597\n",
            "0.0\n",
            "0.0\n",
            "nan\n",
            "-0.19256266335695982\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "0.366708640929872\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "invalid value encountered in double_scalars\n",
            "invalid value encountered in double_scalars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test.features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91R6BUxESJsM",
        "outputId": "e303f5bb-b4ce-4e31-bdbe-d3b70b33814c"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [1. 1. 0. ... 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [1. 1. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "L0TQTG1Wh2k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_a.protected_attributes)\n",
        "print(eval_a.protected_attribute_names)\n",
        "print(eval_a.privileged_protected_attributes)\n",
        "print(eval_a.features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL4qs3dzOnAM",
        "outputId": "d674666a-37ea-43a8-fb50-239a40f13ef6"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " ...\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n",
            "['race', 'sex']\n",
            "[array([0.]), array([0.])]\n",
            "[[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in eval_a.protected_attributes:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "_NtuS1cLQJ4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "scoring = ['accuracy']\n",
        "learner = LogisticRegression(solver='liblinear', random_state=1, C = 0.01, penalty = \"l2\") \n",
        "scores = cross_validate(learner, X_train, y_train, scoring=scoring, cv = 5)"
      ],
      "metadata": {
        "id": "_zAd_Qvh-zDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQglo83SAb1f",
        "outputId": "4055891b-0b21-466f-a318-9f38093c1e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.12234139, 0.19997263, 0.14443493, 0.15501308, 0.12455058]),\n",
              " 'score_time': array([0.00662827, 0.00860167, 0.00227618, 0.00251174, 0.0027256 ]),\n",
              " 'test_accuracy': array([0.79789412, 0.80242761, 0.80783855, 0.80535244, 0.8067866 ])}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values_C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "scores_array = {}\n",
        "for value in values_C: \n",
        "  scoring = ['accuracy']\n",
        "  learner = LogisticRegression(solver='liblinear', random_state=1, C = value, penalty = \"l2\") \n",
        "  scores = cross_validate(learner, X_train, y_train, scoring=scoring, cv = 5)\n",
        "  average_accuracy = np.mean(scores['test_accuracy'])\n",
        "  print(average_accuracy)\n",
        "  scores_array[value] = np.append(scores['test_accuracy'], average_accuracy)\n",
        "\n",
        "# print(scores_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH5FKQi4AdOe",
        "outputId": "930967bf-409b-4fa7-f0f0-da68e259bb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7972155789282572\n",
            "0.8033579011506093\n",
            "0.8040598650658761\n",
            "0.8041476100205415\n",
            "0.8041476100205415\n",
            "0.8041476100205415\n",
            "0.8041476100205415\n",
            "0.8041476100205415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz4KiZ8KA96q",
        "outputId": "52e10fac-a43c-48aa-a82a-3b02e3b04f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0001: array([0.79160573, 0.79540801, 0.80257385, 0.79584674, 0.80064356,\n",
              "        0.79721558]),\n",
              " 0.001: array([0.79789412, 0.80111144, 0.80754607, 0.80359754, 0.80664034,\n",
              "        0.8033579 ]),\n",
              " 0.01: array([0.79789412, 0.80242761, 0.80783855, 0.80535244, 0.8067866 ,\n",
              "        0.80405987]),\n",
              " 0.1: array([0.79833285, 0.80242761, 0.80783855, 0.80535244, 0.8067866 ,\n",
              "        0.80414761]),\n",
              " 1: array([0.79833285, 0.80242761, 0.80783855, 0.80535244, 0.8067866 ,\n",
              "        0.80414761]),\n",
              " 10: array([0.79833285, 0.80242761, 0.80783855, 0.80535244, 0.8067866 ,\n",
              "        0.80414761]),\n",
              " 100: array([0.79833285, 0.80242761, 0.80783855, 0.80535244, 0.8067866 ,\n",
              "        0.80414761]),\n",
              " 1000: array([0.79833285, 0.80242761, 0.80783855, 0.80535244, 0.8067866 ,\n",
              "        0.80414761])}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I want to also add in my other metrics in CV. Let's see if they work. "
      ],
      "metadata": {
        "id": "Afp3ycZ9EOmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = ClassificationMetric(test, test_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "metric.statistical_parity_difference()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAFxedBwDDAn",
        "outputId": "174520ad-f4e6-488c-a7cd-54274af5ba52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.20557244174265452"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def statistical_parity_fn(y_true, y_pred):\n",
        "  metric = ClassificationMetric(y_true, y_pred, unprivileged_groups, privileged_groups)\n",
        "  return metric.statistical_parity_difference()\n",
        "\n",
        "statistical_parity = make_scorer(statistical_parity_fn)"
      ],
      "metadata": {
        "id": "Mri6a_47Eje4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values_C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "scores_array = {}\n",
        "for value in values_C: \n",
        "  # scoring = ['accuracy', statistical_parity]\n",
        "  scoring = {'accuracy': 'accuracy',\n",
        "            'statistical parity': statistical_parity}\n",
        "  learner = LogisticRegression(solver='liblinear', random_state=1, C = value, penalty = \"l2\") \n",
        "  scores = cross_validate(learner, X_train, y_train, scoring=scoring, cv = 5)\n",
        "  average_accuracy = np.mean(scores['test_accuracy'])\n",
        "  print(average_accuracy)\n",
        "  scores_array[value] = np.append(scores['test_accuracy'], average_accuracy)\n",
        "\n",
        "# print(scores_array)"
      ],
      "metadata": {
        "id": "aPWc9blfFGjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M7p2B3VCGyuM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}